{"version":3,"file":"static/js/vendor.micromark.0eefd6eebbcf2c0ca8b3.js","mappings":"0UAaO,MAAMA,EAAU,CACrBC,SASF,SAA2BC,GACzB,MAAMC,EAAeD,EAAQE,QAAQC,KAAKC,OAAOC,WAAWC,gBAM5D,SAAoCC,GAClC,GAAa,OAATA,EAEF,YADAP,EAAQQ,QAAQD,GAMlB,OAHAP,EAAQS,MAAM,cACdT,EAAQQ,QAAQD,GAChBP,EAAQU,KAAK,eACN,OAAaV,EAASC,EAAc,aAC7C,IAGA,SAA0BM,GAExB,OADAP,EAAQS,MAAM,aACPE,EAAUJ,EACnB,IAnBA,IAAIK,EACJ,OAAOX,EAqBP,SAASU,EAAUJ,GACjB,MAAMM,EAAQb,EAAQS,MAAM,YAAa,CACvCK,YAAa,OACbF,aAMF,OAJIA,IACFA,EAASG,KAAOF,GAElBD,EAAWC,EACJG,EAAKT,EACd,CAGA,SAASS,EAAKT,GACZ,OAAa,OAATA,GACFP,EAAQU,KAAK,aACbV,EAAQU,KAAK,kBACbV,EAAQQ,QAAQD,KAGd,QAAmBA,IACrBP,EAAQQ,QAAQD,GAChBP,EAAQU,KAAK,aACNC,IAITX,EAAQQ,QAAQD,GACTS,EACT,CACF,G,cCvDO,MAAM,EAAW,CACtBjB,SAcF,SAA4BC,GAC1B,MAAMiB,EAAOd,KAEPe,EAAQ,GACd,IAEIC,EAEAC,EAEAC,EANAC,EAAY,EAOhB,OAAOC,EAGP,SAASA,EAAMhB,GAWb,GAAIe,EAAYJ,EAAMM,OAAQ,CAC5B,MAAMC,EAAOP,EAAMI,GAEnB,OADAL,EAAKS,eAAiBD,EAAK,GACpBzB,EAAQE,QAAQuB,EAAK,GAAGE,aAAcC,EAAkBC,EAAxD7B,CAA4EO,EACrF,CAGA,OAAOsB,EAAmBtB,EAC5B,CAGA,SAASqB,EAAiBrB,GAMxB,GALAe,IAKIL,EAAKS,eAAeI,WAAY,CAClCb,EAAKS,eAAeI,gBAAaC,EAC7BZ,GACFa,IAKF,MAAMC,EAAmBhB,EAAKiB,OAAOV,OACrC,IAEIW,EAFAC,EAAkBH,EAKtB,KAAOG,KACL,GAAwC,SAApCnB,EAAKiB,OAAOE,GAAiB,IAA0D,cAAzCnB,EAAKiB,OAAOE,GAAiB,GAAGC,KAAsB,CACtGF,EAAQlB,EAAKiB,OAAOE,GAAiB,GAAGE,IACxC,KACF,CAEFC,EAAejB,GAGf,IAAIkB,EAAQP,EACZ,KAAOO,EAAQvB,EAAKiB,OAAOV,QACzBP,EAAKiB,OAAOM,GAAO,GAAGF,IAAM,IACvBH,GAELK,IAQF,OAJA,OAAOvB,EAAKiB,OAAQE,EAAkB,EAAG,EAAGnB,EAAKiB,OAAOO,MAAMR,IAG9DhB,EAAKiB,OAAOV,OAASgB,EACdX,EAAmBtB,EAC5B,CACA,OAAOgB,EAAMhB,EACf,CAGA,SAASsB,EAAmBtB,GAM1B,GAAIe,IAAcJ,EAAMM,OAAQ,CAI9B,IAAKL,EACH,OAAOuB,EAAkBnC,GAM3B,GAAIY,EAAUwB,kBAAoBxB,EAAUwB,iBAAiBC,SAC3D,OAAOC,EAAUtC,GAQnBU,EAAK6B,UAAYC,QAAQ5B,EAAUwB,mBAAqBxB,EAAU6B,8BACpE,CAIA,OADA/B,EAAKS,eAAiB,CAAC,EAChB1B,EAAQiD,MAAMC,EAAoBC,EAAsBC,EAAxDpD,CAA+EO,EACxF,CAGA,SAAS4C,EAAqB5C,GAG5B,OAFIY,GAAWa,IACfO,EAAejB,GACRoB,EAAkBnC,EAC3B,CAGA,SAAS6C,EAAsB7C,GAG7B,OAFAU,EAAKb,OAAOiD,KAAKpC,EAAKqC,MAAMC,MAAQjC,IAAcJ,EAAMM,OACxDH,EAAkBJ,EAAKqC,MAAME,OACtBX,EAAUtC,EACnB,CAGA,SAASmC,EAAkBnC,GAGzB,OADAU,EAAKS,eAAiB,CAAC,EAChB1B,EAAQE,QAAQgD,EAAoBO,EAAmBZ,EAAvD7C,CAAkEO,EAC3E,CAGA,SAASkD,EAAkBlD,GAIzB,OAHAe,IACAJ,EAAMwC,KAAK,CAACzC,EAAK0B,iBAAkB1B,EAAKS,iBAEjCgB,EAAkBnC,EAC3B,CAGA,SAASsC,EAAUtC,GACjB,OAAa,OAATA,GACEY,GAAWa,IACfO,EAAe,QACfvC,EAAQQ,QAAQD,KAGlBY,EAAYA,GAAaF,EAAKb,OAAOuD,KAAK1C,EAAKqC,OAC/CtD,EAAQS,MAAM,YAAa,CACzBmD,WAAYzC,EACZL,YAAa,OACbF,SAAUQ,IAELyC,EAAatD,GACtB,CAGA,SAASsD,EAAatD,GACpB,OAAa,OAATA,GACFuD,EAAa9D,EAAQU,KAAK,cAAc,GACxC6B,EAAe,QACfvC,EAAQQ,QAAQD,KAGd,QAAmBA,IACrBP,EAAQQ,QAAQD,GAChBuD,EAAa9D,EAAQU,KAAK,cAE1BY,EAAY,EACZL,EAAK6B,eAAYf,EACVR,IAETvB,EAAQQ,QAAQD,GACTsD,EACT,CAUA,SAASC,EAAajD,EAAOkD,GAC3B,MAAMC,EAAS/C,EAAKgD,YAAYpD,GAyChC,GAxCIkD,GAAWC,EAAON,KAAK,MAC3B7C,EAAMD,SAAWQ,EACbA,IAAYA,EAAWL,KAAOF,GAClCO,EAAaP,EACbM,EAAU+C,WAAWrD,EAAMU,OAC3BJ,EAAUgD,MAAMH,GAmCZ/C,EAAKb,OAAOiD,KAAKxC,EAAMU,MAAMgC,MAAO,CACtC,IAAIf,EAAQrB,EAAUe,OAAOV,OAC7B,KAAOgB,KACL,GAEArB,EAAUe,OAAOM,GAAO,GAAGjB,MAAMiC,OAASnC,KAEzCF,EAAUe,OAAOM,GAAO,GAAGF,KAE5BnB,EAAUe,OAAOM,GAAO,GAAGF,IAAIkB,OAASnC,GAGtC,OAMJ,MAAMY,EAAmBhB,EAAKiB,OAAOV,OACrC,IAEI4C,EAEAjC,EAJAC,EAAkBH,EAOtB,KAAOG,KACL,GAAwC,SAApCnB,EAAKiB,OAAOE,GAAiB,IAA0D,cAAzCnB,EAAKiB,OAAOE,GAAiB,GAAGC,KAAsB,CACtG,GAAI+B,EAAM,CACRjC,EAAQlB,EAAKiB,OAAOE,GAAiB,GAAGE,IACxC,KACF,CACA8B,GAAO,CACT,CAMF,IAJA7B,EAAejB,GAGfkB,EAAQP,EACDO,EAAQvB,EAAKiB,OAAOV,QACzBP,EAAKiB,OAAOM,GAAO,GAAGF,IAAM,IACvBH,GAELK,KAIF,OAAOvB,EAAKiB,OAAQE,EAAkB,EAAG,EAAGnB,EAAKiB,OAAOO,MAAMR,IAG9DhB,EAAKiB,OAAOV,OAASgB,CACvB,CACF,CAQA,SAASD,EAAe8B,GACtB,IAAI7B,EAAQtB,EAAMM,OAGlB,KAAOgB,KAAU6B,GAAM,CACrB,MAAMC,EAAQpD,EAAMsB,GACpBvB,EAAKS,eAAiB4C,EAAM,GAC5BA,EAAM,GAAG5D,KAAK6D,KAAKtD,EAAMjB,EAC3B,CACAkB,EAAMM,OAAS6C,CACjB,CACA,SAASrC,IACPb,EAAUgD,MAAM,CAAC,OACjB/C,OAAaW,EACbZ,OAAYY,EACZd,EAAKS,eAAeI,gBAAaC,CACnC,CACF,GAjUMmB,EAAqB,CACzBnD,SAwUF,SAA2BC,EAASwE,EAAIC,GAGtC,OAAO,OAAazE,EAASA,EAAQE,QAAQC,KAAKC,OAAOC,WAAWqE,SAAUF,EAAIC,GAAM,aAActE,KAAKC,OAAOC,WAAWsE,QAAQC,KAAKC,SAAS,qBAAkB9C,EAAY,EACnL,G,wBC5VO,MAAM4B,EAAO,CAClB5D,SASF,SAAwBC,GACtB,MAAMiB,EAAOd,KACP2E,EAAU9E,EAAQE,QAExB,KAMA,SAAuBK,GACrB,GAAa,OAATA,EAEF,YADAP,EAAQQ,QAAQD,GAOlB,OAJAP,EAAQS,MAAM,mBACdT,EAAQQ,QAAQD,GAChBP,EAAQU,KAAK,mBACbO,EAAK0B,sBAAmBZ,EACjB+C,CACT,GAdA9E,EAAQE,QAAQC,KAAKC,OAAOC,WAAW0E,YAAaC,GAAgB,OAAahF,EAASA,EAAQE,QAAQC,KAAKC,OAAOC,WAAWsD,KAAMqB,EAAgBhF,EAAQE,QAAQ,IAAS8E,IAAkB,gBAClM,OAAOF,EAgBP,SAASE,EAAezE,GACtB,GAAa,OAATA,EAQJ,OAJAP,EAAQS,MAAM,cACdT,EAAQQ,QAAQD,GAChBP,EAAQU,KAAK,cACbO,EAAK0B,sBAAmBZ,EACjB+C,EAPL9E,EAAQQ,QAAQD,EAQpB,CACF,GC9CO,MAAM0E,EAAW,CACtBC,WAAYC,KAEDC,EAASC,EAAkB,UAC3B,EAAOA,EAAkB,QAQtC,SAASA,EAAkBC,GACzB,MAAO,CACLJ,WAAYC,EAAyB,SAAVG,EAAmBC,OAAyBxD,GACvEhC,SAQF,SAAwBC,GACtB,MAAMiB,EAAOd,KACPE,EAAaF,KAAKC,OAAOC,WAAWiF,GACpCE,EAAOxF,EAAQE,QAAQG,EAAYkB,EAAOkE,GAChD,OAAOlE,EAGP,SAASA,EAAMhB,GACb,OAAOmF,EAAQnF,GAAQiF,EAAKjF,GAAQkF,EAAQlF,EAC9C,CAGA,SAASkF,EAAQlF,GACf,GAAa,OAATA,EAMJ,OAFAP,EAAQS,MAAM,QACdT,EAAQQ,QAAQD,GACTS,EALLhB,EAAQQ,QAAQD,EAMpB,CAGA,SAASS,EAAKT,GACZ,OAAImF,EAAQnF,IACVP,EAAQU,KAAK,QACN8E,EAAKjF,KAIdP,EAAQQ,QAAQD,GACTS,EACT,CAQA,SAAS0E,EAAQnF,GACf,GAAa,OAATA,EACF,OAAO,EAET,MAAMoF,EAAOtF,EAAWE,GACxB,IAAIiC,GAAS,EACb,GAAImD,EAGF,OAASnD,EAAQmD,EAAKnE,QAAQ,CAC5B,MAAMC,EAAOkE,EAAKnD,GAClB,IAAKf,EAAKb,UAAYa,EAAKb,SAAS2D,KAAKtD,EAAMA,EAAKL,UAClD,OAAO,CAEX,CAEF,OAAO,CACT,CACF,EACF,CAQA,SAASuE,EAAeS,GACtB,OAGA,SAAwB1D,EAAQ2D,GAC9B,IAEIpF,EAFA+B,GAAS,EAMb,OAASA,GAASN,EAAOV,aACTO,IAAVtB,EACEyB,EAAOM,IAAoC,SAA1BN,EAAOM,GAAO,GAAGH,OACpC5B,EAAQ+B,EACRA,KAEQN,EAAOM,IAAoC,SAA1BN,EAAOM,GAAO,GAAGH,OAExCG,IAAU/B,EAAQ,IACpByB,EAAOzB,GAAO,GAAG6B,IAAMJ,EAAOM,EAAQ,GAAG,GAAGF,IAC5CJ,EAAO4D,OAAOrF,EAAQ,EAAG+B,EAAQ/B,EAAQ,GACzC+B,EAAQ/B,EAAQ,GAElBA,OAAQsB,GAGZ,OAAO6D,EAAgBA,EAAc1D,EAAQ2D,GAAW3D,CAC1D,CACF,CAaA,SAASqD,EAAuBrD,EAAQ2D,GACtC,IAAIE,EAAa,EAEjB,OAASA,GAAc7D,EAAOV,QAC5B,IAAKuE,IAAe7D,EAAOV,QAAyC,eAA/BU,EAAO6D,GAAY,GAAG1D,OAA6D,SAAnCH,EAAO6D,EAAa,GAAG,GAAG1D,KAAiB,CAC9H,MAAMrB,EAAOkB,EAAO6D,EAAa,GAAG,GAC9BC,EAASH,EAAQ5B,YAAYjD,GACnC,IAIIiF,EAJAzD,EAAQwD,EAAOxE,OACf0E,GAAe,EACf7B,EAAO,EAGX,KAAO7B,KAAS,CACd,MAAM2D,EAAQH,EAAOxD,GACrB,GAAqB,iBAAV2D,EAAoB,CAE7B,IADAD,EAAcC,EAAM3E,OACyB,KAAtC2E,EAAMC,WAAWF,EAAc,IACpC7B,IACA6B,IAEF,GAAIA,EAAa,MACjBA,GAAe,CACjB,MAEK,IAAe,IAAXC,EACPF,GAAO,EACP5B,SACK,IAAe,IAAX8B,EAEJ,CAEL3D,IACA,KACF,CACF,CACA,GAAI6B,EAAM,CACR,MAAMxD,EAAQ,CACZwB,KAAM0D,IAAe7D,EAAOV,QAAUyE,GAAQ5B,EAAO,EAAI,aAAe,oBACxE9C,MAAO,CACL8E,aAAc7D,EAAQ0D,EAAclF,EAAKO,MAAM8E,aAAeH,EAC9DI,OAAQtF,EAAKO,MAAM+E,OAAS9D,EAC5Be,KAAMvC,EAAKsB,IAAIiB,KACfgD,OAAQvF,EAAKsB,IAAIiE,OAASlC,EAC1Bb,OAAQxC,EAAKsB,IAAIkB,OAASa,GAE5B/B,IAAK,IACAtB,EAAKsB,MAGZtB,EAAKsB,IAAM,IACNzB,EAAMU,OAEPP,EAAKO,MAAMiC,SAAWxC,EAAKsB,IAAIkB,OACjCgD,OAAOC,OAAOzF,EAAMH,IAEpBqB,EAAO4D,OAAOC,EAAY,EAAG,CAAC,QAASlF,EAAOgF,GAAU,CAAC,OAAQhF,EAAOgF,IACxEE,GAAc,EAElB,CACAA,GACF,CAEF,OAAO7D,CACT,C,yMCtMO,MAAM,EAAW,CACtB,GAAMyD,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAM,KAIKrF,EAAiB,CAC5B,GAAMoG,EAAA,GAIK3B,EAAc,CACzB,EAAE,GAAI,IACN,EAAE,GAAI,IACN,GAAM,KAIK,EAAO,CAClB,GAAM,IACN,GAAM,IACN,GAAM,CAAC,IAAiB,KACxB,GAAM,IACN,GAAM,IACN,GAAM,IACN,GAAM,IACN,IAAO,KAII,EAAS,CACpB,GAAM,IACN,GAAM,KAIK,EAAO,CAClB,EAAE,GAAI,IACN,EAAE,GAAI,IACN,EAAE,GAAI,IACN,GAAM,IACN,GAAM,IACN,GAAM4B,EAAA,EACN,GAAM,CAACC,EAAA,EAAU,KACjB,GAAM,IACN,GAAM,CAAC,IAAiB,KACxB,GAAM,IACN,GAAMD,EAAA,EACN,GAAM,KAIKE,EAAa,CACxBjC,KAAM,CAAC+B,EAAA,EAAW,IAIPG,EAAmB,CAC9BlC,KAAM,CAAC,GAAI,KAIAD,EAAU,CACrBC,KAAM,I,cCvBD,SAASmC,EAAgB3G,EAAQ4G,EAAYC,GAElD,IAAI9E,EAAQ,CACVkE,cAAe,EACfC,OAAQ,EACR/C,KAAM0D,GAAQA,EAAK1D,MAAQ,EAC3BgD,OAAQU,GAAQA,EAAKV,QAAU,EAC/B/C,OAAQyD,GAAQA,EAAKzD,QAAU,GAGjC,MAAM0D,EAAc,CAAC,EAEfC,EAAuB,GAE7B,IAAInB,EAAS,GAET9E,EAAQ,GAERkG,GAAW,EAOf,MAAMpH,EAAU,CACdE,QAASmH,GAoNX,SAA+BC,EAAWC,GACxCC,EAAUF,EAAWC,EAAKN,KAC5B,IArNEhE,MAAOoE,EAAiBI,GACxBjH,QAsJF,SAAiBD,IACX,QAAmBA,IACrB4B,EAAMoB,OACNpB,EAAMoE,OAAS,EACfpE,EAAMqB,SAAoB,IAAVjD,EAAc,EAAI,EAClCmH,MACmB,IAAVnH,IACT4B,EAAMoE,SACNpE,EAAMqB,UAIJrB,EAAMkE,aAAe,EACvBlE,EAAMmE,UAENnE,EAAMkE,eAGFlE,EAAMkE,eAIVL,EAAO7D,EAAMmE,QAAQ9E,SACnBW,EAAMkE,cAAgB,EACtBlE,EAAMmE,WAKVT,EAAQjF,SAAWL,EAGnB6G,GAAW,CACb,EAtLE3G,MAyLF,SAAe4B,EAAMsF,GAGnB,MAAM9G,EAAQ8G,GAAU,CAAC,EAKzB,OAJA9G,EAAMwB,KAAOA,EACbxB,EAAMU,MAAQ+B,IACduC,EAAQ3D,OAAOwB,KAAK,CAAC,QAAS7C,EAAOgF,IACrC3E,EAAMwC,KAAK7C,GACJA,CACT,EAjMEH,KAoMF,SAAc2B,GACZ,MAAMxB,EAAQK,EAAM0G,MAGpB,OAFA/G,EAAMyB,IAAMgB,IACZuC,EAAQ3D,OAAOwB,KAAK,CAAC,OAAQ7C,EAAOgF,IAC7BhF,CACT,EAxMEiC,UAAWuE,EAAiBI,EAAmB,CAC7C3E,WAAW,KAST+C,EAAU,CACdtF,KAAM,KACNmB,eAAgB,CAAC,EACjBwC,WA8EF,SAAoB2D,GAClBX,EAAYW,EAAMtE,MAAQsE,EAAMtB,OAChCmB,GACF,EAhFExF,OAAQ,GACRoB,MACAlD,SACAQ,SAAU,KACVkH,eA4CF,SAAwBjH,EAAOkH,GAC7B,OAsZJ,SAAyB/B,EAAQ+B,GAC/B,IAAIvF,GAAS,EAEb,MAAMwF,EAAS,GAEf,IAAIC,EACJ,OAASzF,EAAQwD,EAAOxE,QAAQ,CAC9B,MAAM2E,EAAQH,EAAOxD,GAErB,IAAIqF,EACJ,GAAqB,iBAAV1B,EACT0B,EAAQ1B,OACH,OAAQA,GACb,KAAM,EAEF0B,EAAQ,KACR,MAEJ,KAAM,EAEFA,EAAQ,KACR,MAEJ,KAAM,EAEFA,EAAQ,OACR,MAEJ,KAAM,EAEFA,EAAQE,EAAa,IAAM,KAC3B,MAEJ,KAAM,EAEF,IAAKA,GAAcE,EAAO,SAC1BJ,EAAQ,IACR,MAEJ,QAGIA,EAAQK,OAAOC,aAAahC,GAGlC8B,GAAmB,IAAX9B,EACR6B,EAAOtE,KAAKmE,EACd,CACA,OAAOG,EAAOI,KAAK,GACrB,CAvcWC,CAAgBpE,EAAYpD,GAAQkH,EAC7C,EA7CE9D,cACAE,MAsBF,SAAe1B,GAKb,GAJAuD,GAAS,OAAKA,EAAQvD,GACtB6F,IAGkC,OAA9BtC,EAAOA,EAAOxE,OAAS,GACzB,MAAO,GAMT,OAJAgG,EAAUR,EAAY,GAGtBnB,EAAQ3D,QAAS,OAAWiF,EAAsBtB,EAAQ3D,OAAQ2D,GAC3DA,EAAQ3D,MACjB,GA3BA,IAOIqG,EAPAC,EAAQxB,EAAWjH,SAASwE,KAAKsB,EAAS7F,GAW9C,OAHIgH,EAAW9B,YACbiC,EAAqBzD,KAAKsD,GAErBnB,EA4BP,SAAS5B,EAAYpD,GACnB,OA2WJ,SAAqBmF,EAAQnF,GAC3B,MAAM4H,EAAa5H,EAAMU,MAAM+E,OACzBoC,EAAmB7H,EAAMU,MAAM8E,aAC/BsC,EAAW9H,EAAMyB,IAAIgE,OACrBsC,EAAiB/H,EAAMyB,IAAI+D,aAEjC,IAAIwC,EACJ,GAAIJ,IAAeE,EAEjBE,EAAO,CAAC7C,EAAOyC,GAAYhG,MAAMiG,EAAkBE,QAC9C,CAEL,GADAC,EAAO7C,EAAOvD,MAAMgG,EAAYE,GAC5BD,GAAoB,EAAG,CACzB,MAAMI,EAAOD,EAAK,GACE,iBAATC,EACTD,EAAK,GAAKC,EAAKrG,MAAMiG,GAErBG,EAAKE,OAET,CACIH,EAAiB,GAEnBC,EAAKnF,KAAKsC,EAAO2C,GAAUlG,MAAM,EAAGmG,GAExC,CACA,OAAOC,CACT,CArYWG,CAAYhD,EAAQnF,EAC7B,CAGA,SAASyC,IAEP,MAAM,aACJ+C,EAAY,OACZC,EAAM,KACN/C,EAAI,OACJgD,EAAM,OACN/C,GACErB,EACJ,MAAO,CACLkE,eACAC,SACA/C,OACAgD,SACA/C,SAEJ,CAuBA,SAAS8E,IAEP,IAAIW,EACJ,KAAO9G,EAAMmE,OAASN,EAAOxE,QAAQ,CACnC,MAAM2E,EAAQH,EAAO7D,EAAMmE,QAG3B,GAAqB,iBAAVH,EAKT,IAJA8C,EAAa9G,EAAMmE,OACfnE,EAAMkE,aAAe,IACvBlE,EAAMkE,aAAe,GAEhBlE,EAAMmE,SAAW2C,GAAc9G,EAAMkE,aAAeF,EAAM3E,QAC/D0H,EAAG/C,EAAMC,WAAWjE,EAAMkE,oBAG5B6C,EAAG/C,EAEP,CACF,CAUA,SAAS+C,EAAG3I,GACV6G,OAAWrF,EACXwG,EAAehI,EACfiI,EAAQA,EAAMjI,EAChB,CAwEA,SAASkH,EAAkB0B,EAAG5B,GAC5BA,EAAK6B,SACP,CAUA,SAAS/B,EAAiBgC,EAAU1B,GAClC,OAeA,SAActH,EAAYiJ,EAAaC,GAErC,IAAIC,EAEAC,EAEA9G,EAEA4E,EACJ,OAAOmC,MAAMC,QAAQtJ,GACrBuJ,EAAuBvJ,GAAc,aAAcA,EAEnDuJ,EAAuB,CAAC,IAUxB,SAA+BC,GAC7B,OAAOtI,EAGP,SAASA,EAAMhB,GACb,MAAMuJ,EAAgB,OAATvJ,GAAiBsJ,EAAItJ,GAC5BwJ,EAAe,OAATxJ,GAAiBsJ,EAAIjF,KAKjC,OAAOgF,EAJM,IAGTF,MAAMC,QAAQG,GAAQA,EAAOA,EAAO,CAACA,GAAQ,MAASJ,MAAMC,QAAQI,GAAOA,EAAMA,EAAM,CAACA,GAAO,IAC5FH,CAA6BrJ,EACtC,CACF,CAvBiEyJ,CAAsB3J,GAiCvF,SAASuJ,EAAuBjE,GAG9B,OAFA6D,EAAmB7D,EACnB8D,EAAiB,EACG,IAAhB9D,EAAKnE,OACA+H,EAEFU,EAAgBtE,EAAK8D,GAC9B,CAUA,SAASQ,EAAgB3C,GACvB,OAGA,SAAe/G,GAKbgH,EAgER,WACE,MAAM2C,EAAa5G,IACb6G,EAAgBtE,EAAQjF,SACxBwJ,EAAwBvE,EAAQlD,iBAChC0H,EAAmBxE,EAAQ3D,OAAOV,OAClC8I,EAAaZ,MAAMzC,KAAK/F,GAC9B,MAAO,CACL+F,KAAMoD,EACNjB,WASF,SAASA,IACPjH,EAAQ+H,EACRrE,EAAQjF,SAAWuJ,EACnBtE,EAAQlD,iBAAmByH,EAC3BvE,EAAQ3D,OAAOV,OAAS6I,EACxBnJ,EAAQoJ,EACR5C,GACF,CACF,CAzFe6C,GACP5H,EAAmB2E,EACdA,EAAUkD,UACb3E,EAAQlD,iBAAmB2E,GAK7B,GAAIA,EAAUmD,MAAQ5E,EAAQzF,OAAOC,WAAWsE,QAAQC,KAAKC,SAASyC,EAAUmD,MAC9E,OAAOhG,EAAIlE,GAEb,OAAO+G,EAAUvH,SAASwE,KAI1BoD,EAASnB,OAAOC,OAAOD,OAAOkE,OAAO7E,GAAU8B,GAAU9B,EAAS7F,EAASwE,EAAIC,EAJxE6C,CAI6E/G,EACtF,CACF,CAGA,SAASiE,EAAGjE,GAGV,OAFA6G,GAAW,EACXiC,EAAS1G,EAAkB4E,GACpB+B,CACT,CAGA,SAAS7E,EAAIlE,GAGX,OAFA6G,GAAW,EACXG,EAAK6B,YACCK,EAAiBD,EAAiBhI,OAC/ByI,EAAgBT,EAAiBC,IAEnCF,CACT,CACF,CACF,CAUA,SAAS/B,EAAUF,EAAWL,GACxBK,EAAUpC,aAAeiC,EAAqBtC,SAASyC,IACzDH,EAAqBzD,KAAK4D,GAExBA,EAAUqD,UACZ,OAAO9E,EAAQ3D,OAAQ+E,EAAMpB,EAAQ3D,OAAOV,OAASyF,EAAMK,EAAUqD,QAAQ9E,EAAQ3D,OAAOO,MAAMwE,GAAOpB,IAEvGyB,EAAUsD,YACZ/E,EAAQ3D,OAASoF,EAAUsD,UAAU/E,EAAQ3D,OAAQ2D,GAEzD,CA0CA,SAAS6B,IACHvF,EAAMoB,QAAQ2D,GAAe/E,EAAMoE,OAAS,IAC9CpE,EAAMoE,OAASW,EAAY/E,EAAMoB,MACjCpB,EAAMqB,QAAU0D,EAAY/E,EAAMoB,MAAQ,EAE9C,CACF,CCteO,SAASsH,EAAMC,GACpB,MAAMC,EAAWD,GAAW,CAAC,EAKvB1K,EAAS,CACbC,YAJF,OAAkB,CAAC,KAAuB0K,EAASC,YAAc,KAK/DlL,QAAS4K,EAAO5K,GAChBmL,QAAS,GACTvG,SAAUgG,EAAO,GACjB/G,KAAM+G,EAAO/G,GACbN,KAAM,CAAC,EACP+B,OAAQsF,EAAOtF,GACfI,KAAMkF,EAAO,IAEf,OAAOtK,EAQP,SAASsK,EAAO5F,GACd,OAEA,SAAiBmC,GACf,OAAOF,EAAgB3G,EAAQ0E,EAASmC,EAC1C,CACF,CACF,C,gDC3CO,SAASiE,EAAYhJ,GAC1B,OAAQ,OAAYA,KAGpB,OAAOA,CACT,C,kCCAA,MAAMiJ,EAAS,cAMR,SAASC,IACd,IAKIC,EALA9E,EAAS,EACT+E,EAAS,GAET/J,GAAQ,EAGZ,OAIA,SAAsBsG,EAAO0D,EAAUjJ,GAErC,MAAM0D,EAAS,GAEf,IAAIwF,EAEAzK,EAEA0K,EAEAC,EAEAnL,EACJsH,EAAQyD,GAA2B,iBAAVzD,EAAqBA,EAAM8D,WAAa,IAAIC,YAAYL,QAAYxJ,GAAW8J,OAAOhE,IAC/G4D,EAAgB,EAChBH,EAAS,GACL/J,IAE0B,QAAxBsG,EAAMzB,WAAW,IACnBqF,IAEFlK,OAAQQ,GAEV,KAAO0J,EAAgB5D,EAAMrG,QAAQ,CAKnC,GAJA2J,EAAOW,UAAYL,EACnBD,EAAQL,EAAOY,KAAKlE,GACpB6D,EAAcF,QAAyBzJ,IAAhByJ,EAAMhJ,MAAsBgJ,EAAMhJ,MAAQqF,EAAMrG,OACvEjB,EAAOsH,EAAMzB,WAAWsF,IACnBF,EAAO,CACVF,EAASzD,EAAMpF,MAAMgJ,GACrB,KACF,CACA,GAAa,KAATlL,GAAekL,IAAkBC,GAAeL,EAClDrF,EAAOtC,MAAM,GACb2H,OAAmBtJ,OAUnB,OARIsJ,IACFrF,EAAOtC,MAAM,GACb2H,OAAmBtJ,GAEjB0J,EAAgBC,IAClB1F,EAAOtC,KAAKmE,EAAMpF,MAAMgJ,EAAeC,IACvCnF,GAAUmF,EAAcD,GAElBlL,GACN,KAAK,EAEDyF,EAAOtC,KAAK,OACZ6C,IACA,MAEJ,KAAK,EAID,IAFAxF,EAA+B,EAAxBiL,KAAKC,KAAK1F,EAAS,GAC1BP,EAAOtC,MAAM,GACN6C,IAAWxF,GAAMiF,EAAOtC,MAAM,GACrC,MAEJ,KAAK,GAEDsC,EAAOtC,MAAM,GACb6C,EAAS,EACT,MAEJ,QAEI8E,GAAmB,EACnB9E,EAAS,EAIjBkF,EAAgBC,EAAc,CAChC,CACIpJ,IACE+I,GAAkBrF,EAAOtC,MAAM,GAC/B4H,GAAQtF,EAAOtC,KAAK4H,GACxBtF,EAAOtC,KAAK,OAEd,OAAOsC,CACT,CACF,C","sources":["webpack://silkforest-web/../../node_modules/micromark/lib/initialize/content.js","webpack://silkforest-web/../../node_modules/micromark/lib/initialize/document.js","webpack://silkforest-web/../../node_modules/micromark/lib/initialize/flow.js","webpack://silkforest-web/../../node_modules/micromark/lib/initialize/text.js","webpack://silkforest-web/../../node_modules/micromark/lib/constructs.js","webpack://silkforest-web/../../node_modules/micromark/lib/create-tokenizer.js","webpack://silkforest-web/../../node_modules/micromark/lib/parse.js","webpack://silkforest-web/../../node_modules/micromark/lib/postprocess.js","webpack://silkforest-web/../../node_modules/micromark/lib/preprocess.js"],"sourcesContent":["/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Initializer}\n *   Content.\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(this.parser.constructs.contentInitial, afterContentStartConstruct, paragraphInitial);\n  /** @type {Token} */\n  let previous;\n  return contentStart;\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    return factorySpace(effects, contentStart, \"linePrefix\");\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    effects.enter(\"paragraph\");\n    return lineStart(code);\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter(\"chunkText\", {\n      contentType: \"text\",\n      previous\n    });\n    if (previous) {\n      previous.next = token;\n    }\n    previous = token;\n    return data(code);\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === null) {\n      effects.exit(\"chunkText\");\n      effects.exit(\"paragraph\");\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      effects.exit(\"chunkText\");\n      return lineStart;\n    }\n\n    // Data.\n    effects.consume(code);\n    return data;\n  }\n}","/**\n * @import {\n *   Construct,\n *   ContainerState,\n *   InitialConstruct,\n *   Initializer,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Tokenizer,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n *   Construct and its state.\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { splice } from 'micromark-util-chunked';\n/** @type {InitialConstruct} */\nexport const document = {\n  tokenize: initializeDocument\n};\n\n/** @type {Construct} */\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n};\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeDocument(effects) {\n  const self = this;\n  /** @type {Array<StackItem>} */\n  const stack = [];\n  let continued = 0;\n  /** @type {TokenizeContext | undefined} */\n  let childFlow;\n  /** @type {Token | undefined} */\n  let childToken;\n  /** @type {number} */\n  let lineStartOffset;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued];\n      self.containerState = item[1];\n      return effects.attempt(item[0].continuation, documentContinue, checkNewContainers)(code);\n    }\n\n    // Done.\n    return checkNewContainers(code);\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    continued++;\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined;\n      if (childFlow) {\n        closeFlow();\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === \"chunkFlow\") {\n          point = self.events[indexBeforeFlow][1].end;\n          break;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      let index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = {\n          ...point\n        };\n        index++;\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n      return checkNewContainers(code);\n    }\n    return start(code);\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code);\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code);\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack);\n    }\n\n    // Check if there is a new container.\n    self.containerState = {};\n    return effects.check(containerConstruct, thereIsANewContainer, thereIsNoNewContainer)(code);\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow();\n    exitContainers(continued);\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length;\n    lineStartOffset = self.now().offset;\n    return flowStart(code);\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {};\n    return effects.attempt(containerConstruct, containerContinue, flowStart)(code);\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    continued++;\n    stack.push([self.currentConstruct, self.containerState]);\n    // Try another.\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow();\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    childFlow = childFlow || self.parser.flow(self.now());\n    effects.enter(\"chunkFlow\", {\n      _tokenizer: childFlow,\n      contentType: \"flow\",\n      previous: childToken\n    });\n    return flowContinue(code);\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit(\"chunkFlow\"), true);\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      writeToChild(effects.exit(\"chunkFlow\"));\n      // Get ready for the next line.\n      continued = 0;\n      self.interrupt = undefined;\n      return start;\n    }\n    effects.consume(code);\n    return flowContinue;\n  }\n\n  /**\n   * @param {Token} token\n   *   Token.\n   * @param {boolean | undefined} [endOfFile]\n   *   Whether the token is at the end of the file (default: `false`).\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function writeToChild(token, endOfFile) {\n    const stream = self.sliceStream(token);\n    if (endOfFile) stream.push(null);\n    token.previous = childToken;\n    if (childToken) childToken.next = token;\n    childToken = token;\n    childFlow.defineSkip(token.start);\n    childFlow.write(stream);\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length;\n      while (index--) {\n        if (\n        // The token starts before the line ending…\n        childFlow.events[index][1].start.offset < lineStartOffset && (\n        // …and either is not ended yet…\n        !childFlow.events[index][1].end ||\n        // …or ends after it.\n        childFlow.events[index][1].end.offset > lineStartOffset)) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return;\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {boolean | undefined} */\n      let seen;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === \"chunkFlow\") {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end;\n            break;\n          }\n          seen = true;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = {\n          ...point\n        };\n        index++;\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n    }\n  }\n\n  /**\n   * @param {number} size\n   *   Size.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function exitContainers(size) {\n    let index = stack.length;\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index];\n      self.containerState = entry[1];\n      entry[0].exit.call(self, effects);\n    }\n    stack.length = size;\n  }\n  function closeFlow() {\n    childFlow.write([null]);\n    childToken = undefined;\n    childFlow = undefined;\n    self.containerState._closeFlow = undefined;\n  }\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n *   Tokenizer.\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n\n  return factorySpace(effects, effects.attempt(this.parser.constructs.document, ok, nok), \"linePrefix\", this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4);\n}","/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nimport { blankLine, content } from 'micromark-core-commonmark';\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n};\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeFlow(effects) {\n  const self = this;\n  const initial = effects.attempt(\n  // Try to parse a blank line.\n  blankLine, atBlankEnding,\n  // Try to parse initial flow (essentially, only code).\n  effects.attempt(this.parser.constructs.flowInitial, afterConstruct, factorySpace(effects, effects.attempt(this.parser.constructs.flow, afterConstruct, effects.attempt(content, afterConstruct)), \"linePrefix\")));\n  return initial;\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEndingBlank\");\n    effects.consume(code);\n    effects.exit(\"lineEndingBlank\");\n    self.currentConstruct = undefined;\n    return initial;\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    self.currentConstruct = undefined;\n    return initial;\n  }\n}","/**\n * @import {\n *   Code,\n *   InitialConstruct,\n *   Initializer,\n *   Resolver,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nexport const resolver = {\n  resolveAll: createResolver()\n};\nexport const string = initializeFactory('string');\nexport const text = initializeFactory('text');\n\n/**\n * @param {'string' | 'text'} field\n *   Field.\n * @returns {InitialConstruct}\n *   Construct.\n */\nfunction initializeFactory(field) {\n  return {\n    resolveAll: createResolver(field === 'text' ? resolveAllLineSuffixes : undefined),\n    tokenize: initializeText\n  };\n\n  /**\n   * @this {TokenizeContext}\n   *   Context.\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this;\n    const constructs = this.parser.constructs[field];\n    const text = effects.attempt(constructs, start, notText);\n    return start;\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code);\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code);\n        return;\n      }\n      effects.enter(\"data\");\n      effects.consume(code);\n      return data;\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit(\"data\");\n        return text(code);\n      }\n\n      // Data.\n      effects.consume(code);\n      return data;\n    }\n\n    /**\n     * @param {Code} code\n     *   Code.\n     * @returns {boolean}\n     *   Whether the code is a break.\n     */\n    function atBreak(code) {\n      if (code === null) {\n        return true;\n      }\n      const list = constructs[code];\n      let index = -1;\n      if (list) {\n        // Always populated by defaults.\n\n        while (++index < list.length) {\n          const item = list[index];\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true;\n          }\n        }\n      }\n      return false;\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n *   Resolver.\n * @returns {Resolver}\n *   Resolver.\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText;\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1;\n    /** @type {number | undefined} */\n    let enter;\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === \"data\") {\n          enter = index;\n          index++;\n        }\n      } else if (!events[index] || events[index][1].type !== \"data\") {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end;\n          events.splice(enter + 2, index - enter - 2);\n          index = enter + 2;\n        }\n        enter = undefined;\n      }\n    }\n    return extraResolver ? extraResolver(events, context) : events;\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0; // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if ((eventIndex === events.length || events[eventIndex][1].type === \"lineEnding\") && events[eventIndex - 1][1].type === \"data\") {\n      const data = events[eventIndex - 1][1];\n      const chunks = context.sliceStream(data);\n      let index = chunks.length;\n      let bufferIndex = -1;\n      let size = 0;\n      /** @type {boolean | undefined} */\n      let tabs;\n      while (index--) {\n        const chunk = chunks[index];\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length;\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++;\n            bufferIndex--;\n          }\n          if (bufferIndex) break;\n          bufferIndex = -1;\n        }\n        // Number\n        else if (chunk === -2) {\n          tabs = true;\n          size++;\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++;\n          break;\n        }\n      }\n      if (size) {\n        const token = {\n          type: eventIndex === events.length || tabs || size < 2 ? \"lineSuffix\" : \"hardBreakTrailing\",\n          start: {\n            _bufferIndex: index ? bufferIndex : data.start._bufferIndex + bufferIndex,\n            _index: data.start._index + index,\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size\n          },\n          end: {\n            ...data.end\n          }\n        };\n        data.end = {\n          ...token.start\n        };\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token);\n        } else {\n          events.splice(eventIndex, 0, ['enter', token, context], ['exit', token, context]);\n          eventIndex += 2;\n        }\n      }\n      eventIndex++;\n    }\n  }\n  return events;\n}","/**\n * @import {Extension} from 'micromark-util-types'\n */\n\nimport { attention, autolink, blockQuote, characterEscape, characterReference, codeFenced, codeIndented, codeText, definition, hardBreakEscape, headingAtx, htmlFlow, htmlText, labelEnd, labelStartImage, labelStartLink, lineEnding, list, setextUnderline, thematicBreak } from 'micromark-core-commonmark';\nimport { resolver as resolveText } from './initialize/text.js';\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n};\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [91]: definition\n};\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n};\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n};\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n};\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n};\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {\n  null: [attention, resolveText]\n};\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {\n  null: [42, 95]\n};\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {\n  null: []\n};","/**\n * @import {\n *   Chunk,\n *   Code,\n *   ConstructRecord,\n *   Construct,\n *   Effects,\n *   InitialConstruct,\n *   ParseContext,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @callback Restore\n *   Restore the state.\n * @returns {undefined}\n *   Nothing.\n *\n * @typedef Info\n *   Info.\n * @property {Restore} restore\n *   Restore.\n * @property {number} from\n *   From.\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n *   Construct.\n * @param {Info} info\n *   Info.\n * @returns {undefined}\n *   Nothing.\n */\n\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { push, splice } from 'micromark-util-chunked';\nimport { resolveAll } from 'micromark-util-resolve-all';\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n *   Parser.\n * @param {InitialConstruct} initialize\n *   Construct.\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n *   Point (optional).\n * @returns {TokenizeContext}\n *   Context.\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = {\n    _bufferIndex: -1,\n    _index: 0,\n    line: from && from.line || 1,\n    column: from && from.column || 1,\n    offset: from && from.offset || 0\n  };\n  /** @type {Record<string, number>} */\n  const columnStart = {};\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = [];\n  /** @type {Array<Chunk>} */\n  let chunks = [];\n  /** @type {Array<Token>} */\n  let stack = [];\n  /** @type {boolean | undefined} */\n  let consumed = true;\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    consume,\n    enter,\n    exit,\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  };\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    code: null,\n    containerState: {},\n    defineSkip,\n    events: [],\n    now,\n    parser,\n    previous: null,\n    sliceSerialize,\n    sliceStream,\n    write\n  };\n\n  /**\n   * The state function.\n   *\n   * @type {State | undefined}\n   */\n  let state = initialize.tokenize.call(context, effects);\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode;\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize);\n  }\n  return context;\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice);\n    main();\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return [];\n    }\n    addResult(initialize, 0);\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context);\n    return context.events;\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs);\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token);\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {\n      _bufferIndex,\n      _index,\n      line,\n      column,\n      offset\n    } = point;\n    return {\n      _bufferIndex,\n      _index,\n      line,\n      column,\n      offset\n    };\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column;\n    accountForPotentialSkip();\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex;\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index];\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index;\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0;\n        }\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\n          go(chunk.charCodeAt(point._bufferIndex));\n        }\n      } else {\n        go(chunk);\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   *   Code.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function go(code) {\n    consumed = undefined;\n    expectedCode = code;\n    state = state(code);\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++;\n      point.column = 1;\n      point.offset += code === -3 ? 2 : 1;\n      accountForPotentialSkip();\n    } else if (code !== -1) {\n      point.column++;\n      point.offset++;\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++;\n    } else {\n      point._bufferIndex++;\n\n      // At end of string chunk.\n      if (point._bufferIndex ===\n      // Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      /** @type {string} */\n      chunks[point._index].length) {\n        point._bufferIndex = -1;\n        point._index++;\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code;\n\n    // Mark as consumed.\n    consumed = true;\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {};\n    token.type = type;\n    token.start = now();\n    context.events.push(['enter', token, context]);\n    stack.push(token);\n    return token;\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    const token = stack.pop();\n    token.end = now();\n    context.events.push(['exit', token, context]);\n    return token;\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from);\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore();\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   *   Callback.\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   *   Fields.\n   */\n  function constructFactory(onreturn, fields) {\n    return hook;\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | ConstructRecord | Construct} constructs\n     *   Constructs.\n     * @param {State} returnState\n     *   State.\n     * @param {State | undefined} [bogusState]\n     *   State.\n     * @returns {State}\n     *   State.\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {ReadonlyArray<Construct>} */\n      let listOfConstructs;\n      /** @type {number} */\n      let constructIndex;\n      /** @type {Construct} */\n      let currentConstruct;\n      /** @type {Info} */\n      let info;\n      return Array.isArray(constructs) ? /* c8 ignore next 1 */\n      handleListOfConstructs(constructs) : 'tokenize' in constructs ?\n      // Looks like a construct.\n      handleListOfConstructs([(/** @type {Construct} */constructs)]) : handleMapOfConstructs(constructs);\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleMapOfConstructs(map) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          const left = code !== null && map[code];\n          const all = code !== null && map.null;\n          const list = [\n          // To do: add more extension tests.\n          /* c8 ignore next 2 */\n          ...(Array.isArray(left) ? left : left ? [left] : []), ...(Array.isArray(all) ? all : all ? [all] : [])];\n          return handleListOfConstructs(list)(code);\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ReadonlyArray<Construct>} list\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list;\n        constructIndex = 0;\n        if (list.length === 0) {\n          return bogusState;\n        }\n        return handleConstruct(list[constructIndex]);\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       *   Construct.\n       * @returns {State}\n       *   State.\n       */\n      function handleConstruct(construct) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store();\n          currentConstruct = construct;\n          if (!construct.partial) {\n            context.currentConstruct = construct;\n          }\n\n          // Always populated by defaults.\n\n          if (construct.name && context.parser.constructs.disable.null.includes(construct.name)) {\n            return nok(code);\n          }\n          return construct.tokenize.call(\n          // If we do have fields, create an object w/ `context` as its\n          // prototype.\n          // This allows a “live binding”, which is needed for `interrupt`.\n          fields ? Object.assign(Object.create(context), fields) : context, effects, ok, nok)(code);\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true;\n        onreturn(currentConstruct, info);\n        return returnState;\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true;\n        info.restore();\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex]);\n        }\n        return bogusState;\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   *   Construct.\n   * @param {number} from\n   *   From.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct);\n    }\n    if (construct.resolve) {\n      splice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context);\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   *   Info.\n   */\n  function store() {\n    const startPoint = now();\n    const startPrevious = context.previous;\n    const startCurrentConstruct = context.currentConstruct;\n    const startEventsIndex = context.events.length;\n    const startStack = Array.from(stack);\n    return {\n      from: startEventsIndex,\n      restore\n    };\n\n    /**\n     * Restore state.\n     *\n     * @returns {undefined}\n     *   Nothing.\n     */\n    function restore() {\n      point = startPoint;\n      context.previous = startPrevious;\n      context.currentConstruct = startCurrentConstruct;\n      context.events.length = startEventsIndex;\n      stack = startStack;\n      accountForPotentialSkip();\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line];\n      point.offset += columnStart[point.line] - 1;\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {Pick<Token, 'end' | 'start'>} token\n *   Token.\n * @returns {Array<Chunk>}\n *   Chunks.\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index;\n  const startBufferIndex = token.start._bufferIndex;\n  const endIndex = token.end._index;\n  const endBufferIndex = token.end._bufferIndex;\n  /** @type {Array<Chunk>} */\n  let view;\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];\n  } else {\n    view = chunks.slice(startIndex, endIndex);\n    if (startBufferIndex > -1) {\n      const head = view[0];\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex);\n      } else {\n        view.shift();\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex));\n    }\n  }\n  return view;\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {boolean | undefined} [expandTabs=false]\n *   Whether to expand tabs (default: `false`).\n * @returns {string}\n *   Result.\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1;\n  /** @type {Array<string>} */\n  const result = [];\n  /** @type {boolean | undefined} */\n  let atTab;\n  while (++index < chunks.length) {\n    const chunk = chunks[index];\n    /** @type {string} */\n    let value;\n    if (typeof chunk === 'string') {\n      value = chunk;\n    } else switch (chunk) {\n      case -5:\n        {\n          value = \"\\r\";\n          break;\n        }\n      case -4:\n        {\n          value = \"\\n\";\n          break;\n        }\n      case -3:\n        {\n          value = \"\\r\" + \"\\n\";\n          break;\n        }\n      case -2:\n        {\n          value = expandTabs ? \" \" : \"\\t\";\n          break;\n        }\n      case -1:\n        {\n          if (!expandTabs && atTab) continue;\n          value = \" \";\n          break;\n        }\n      default:\n        {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk);\n        }\n    }\n    atTab = chunk === -2;\n    result.push(value);\n  }\n  return result.join('');\n}","/**\n * @import {\n *   Create,\n *   FullNormalizedExtension,\n *   InitialConstruct,\n *   ParseContext,\n *   ParseOptions\n * } from 'micromark-util-types'\n */\n\nimport { combineExtensions } from 'micromark-util-combine-extensions';\nimport { content } from './initialize/content.js';\nimport { document } from './initialize/document.js';\nimport { flow } from './initialize/flow.js';\nimport { string, text } from './initialize/text.js';\nimport * as defaultConstructs from './constructs.js';\nimport { createTokenizer } from './create-tokenizer.js';\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n *   Configuration (optional).\n * @returns {ParseContext}\n *   Parser.\n */\nexport function parse(options) {\n  const settings = options || {};\n  const constructs = /** @type {FullNormalizedExtension} */\n  combineExtensions([defaultConstructs, ...(settings.extensions || [])]);\n\n  /** @type {ParseContext} */\n  const parser = {\n    constructs,\n    content: create(content),\n    defined: [],\n    document: create(document),\n    flow: create(flow),\n    lazy: {},\n    string: create(string),\n    text: create(text)\n  };\n  return parser;\n\n  /**\n   * @param {InitialConstruct} initial\n   *   Construct to start with.\n   * @returns {Create}\n   *   Create a tokenizer.\n   */\n  function create(initial) {\n    return creator;\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from);\n    }\n  }\n}","/**\n * @import {Event} from 'micromark-util-types'\n */\n\nimport { subtokenize } from 'micromark-util-subtokenize';\n\n/**\n * @param {Array<Event>} events\n *   Events.\n * @returns {Array<Event>}\n *   Events.\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n  return events;\n}","/**\n * @import {Chunk, Code, Encoding, Value} from 'micromark-util-types'\n */\n\n/**\n * @callback Preprocessor\n *   Preprocess a value.\n * @param {Value} value\n *   Value.\n * @param {Encoding | null | undefined} [encoding]\n *   Encoding when `value` is a typed array (optional).\n * @param {boolean | null | undefined} [end=false]\n *   Whether this is the last chunk (default: `false`).\n * @returns {Array<Chunk>}\n *   Chunks.\n */\n\nconst search = /[\\0\\t\\n\\r]/g;\n\n/**\n * @returns {Preprocessor}\n *   Preprocess a value.\n */\nexport function preprocess() {\n  let column = 1;\n  let buffer = '';\n  /** @type {boolean | undefined} */\n  let start = true;\n  /** @type {boolean | undefined} */\n  let atCarriageReturn;\n  return preprocessor;\n\n  /** @type {Preprocessor} */\n  // eslint-disable-next-line complexity\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = [];\n    /** @type {RegExpMatchArray | null} */\n    let match;\n    /** @type {number} */\n    let next;\n    /** @type {number} */\n    let startPosition;\n    /** @type {number} */\n    let endPosition;\n    /** @type {Code} */\n    let code;\n    value = buffer + (typeof value === 'string' ? value.toString() : new TextDecoder(encoding || undefined).decode(value));\n    startPosition = 0;\n    buffer = '';\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++;\n      }\n      start = undefined;\n    }\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition;\n      match = search.exec(value);\n      endPosition = match && match.index !== undefined ? match.index : value.length;\n      code = value.charCodeAt(endPosition);\n      if (!match) {\n        buffer = value.slice(startPosition);\n        break;\n      }\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3);\n        atCarriageReturn = undefined;\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5);\n          atCarriageReturn = undefined;\n        }\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition));\n          column += endPosition - startPosition;\n        }\n        switch (code) {\n          case 0:\n            {\n              chunks.push(65533);\n              column++;\n              break;\n            }\n          case 9:\n            {\n              next = Math.ceil(column / 4) * 4;\n              chunks.push(-2);\n              while (column++ < next) chunks.push(-1);\n              break;\n            }\n          case 10:\n            {\n              chunks.push(-4);\n              column = 1;\n              break;\n            }\n          default:\n            {\n              atCarriageReturn = true;\n              column = 1;\n            }\n        }\n      }\n      startPosition = endPosition + 1;\n    }\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5);\n      if (buffer) chunks.push(buffer);\n      chunks.push(null);\n    }\n    return chunks;\n  }\n}"],"names":["content","tokenize","effects","contentStart","attempt","this","parser","constructs","contentInitial","code","consume","enter","exit","lineStart","previous","token","contentType","next","data","self","stack","childFlow","childToken","lineStartOffset","continued","start","length","item","containerState","continuation","documentContinue","checkNewContainers","_closeFlow","undefined","closeFlow","indexBeforeExits","events","point","indexBeforeFlow","type","end","exitContainers","index","slice","documentContinued","currentConstruct","concrete","flowStart","interrupt","Boolean","_gfmTableDynamicInterruptHack","check","containerConstruct","thereIsANewContainer","thereIsNoNewContainer","lazy","now","line","offset","containerContinue","push","flow","_tokenizer","flowContinue","writeToChild","endOfFile","stream","sliceStream","defineSkip","write","seen","size","entry","call","ok","nok","document","disable","null","includes","initial","flowInitial","afterConstruct","resolver","resolveAll","createResolver","string","initializeFactory","field","resolveAllLineSuffixes","text","notText","atBreak","list","extraResolver","context","splice","eventIndex","chunks","tabs","bufferIndex","chunk","charCodeAt","_bufferIndex","_index","column","Object","assign","definition","attention","autolink","insideSpan","attentionMarkers","createTokenizer","initialize","from","columnStart","resolveAllConstructs","consumed","constructFactory","construct","info","addResult","onsuccessfulcheck","accountForPotentialSkip","fields","pop","value","sliceSerialize","expandTabs","result","atTab","String","fromCharCode","join","serializeChunks","main","expectedCode","state","startIndex","startBufferIndex","endIndex","endBufferIndex","view","head","shift","sliceChunks","chunkIndex","go","_","restore","onreturn","returnState","bogusState","listOfConstructs","constructIndex","Array","isArray","handleListOfConstructs","map","left","all","handleMapOfConstructs","handleConstruct","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","store","partial","name","create","resolve","resolveTo","parse","options","settings","extensions","defined","postprocess","search","preprocess","atCarriageReturn","buffer","encoding","match","startPosition","endPosition","toString","TextDecoder","decode","lastIndex","exec","Math","ceil"],"sourceRoot":""}